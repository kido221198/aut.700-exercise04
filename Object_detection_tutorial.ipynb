{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92c99b33",
   "metadata": {},
   "source": [
    "#   ROS2 | Exercise 4 - Computer Vision\n",
    "\n",
    "##  Task 3 - Object Detection\n",
    "\n",
    "### Pre-requisites\n",
    "Before you begin this Notebook you have to complete the following tasks explained in the handout\n",
    "- [x] Setting up the gazebo simulation as a ROS package\n",
    "- [x] Setting up Conda environment to run this jupyter notebook\n",
    "\n",
    "### Introduction\n",
    "Object detection and its importance in robotics. Opencv Intro. Some images\n",
    "\n",
    "There are 3 parts in this Notebook which covers the following\n",
    "   - 3.1 : Basic Image processing and Opencv contour detection\n",
    "   - 3.2 : Object detection and Tracking with Video\n",
    "   - 3.3 : Object detection and Tracking with ROS2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c766fa",
   "metadata": {},
   "source": [
    "***\n",
    "### 3.1 Basic Image processing with OpenCV \n",
    "\n",
    "### 3.1.1\n",
    "Familiarize yourself with the basic functionalities available in openCV for basic image reading and visualization with this reference [link](https://docs.opencv.org/4.x/db/deb/tutorial_display_image.html). It has both C++ & Python code. We are following python in this notebook. Execute the following code that reads an image file and displays it in an opencv window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637af5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "frame = cv2.imread('image.png')\n",
    "cv2.imshow(\"Tracking\",frame)\n",
    "cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3277af99",
   "metadata": {},
   "source": [
    "### 3.1.2\n",
    "\n",
    "It is important to  pre-process raw input images in computer vision tasks such as object detection and tracking. OpenCV imgproc module contains several functionalities which are often used in image processing.\n",
    "\n",
    "Convertion between color spaces is necessary to generate image masks. Execute and observe the following code where you convert an image from RGB to HSV color space. The code generates a mask of the green color object.\n",
    "\n",
    "**Your task**\n",
    "\n",
    "- [x] Change HSV values in order to generate masks of other objects.\n",
    "\n",
    "**References**\n",
    "- [Concept of HSL and HSV Color spaces](https://en.wikipedia.org/wiki/HSL_and_HSV)\n",
    "- [Opencv basic Image processing functionalities](https://docs.opencv.org/4.x/d7/da8/tutorial_table_of_content_imgproc.html)\n",
    "- [OpenCV RGB-HSV color converstions documentation](https://docs.opencv.org/3.4.6/de/d25/imgproc_color_conversions.html#color_convert_rgb_hsv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a9bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import colorsys\n",
    "import numpy as np\n",
    "\n",
    "frame = cv2.imread('image.png')\n",
    "# cv2.imshow(\"Tracking\",frame)\n",
    "# cv2.waitKey(0) & 0xFF\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "Lower = (0, 86, 6)\n",
    "Upper = (150, 255, 255)\n",
    "\n",
    "# Blue one\n",
    "(r, g, b) = (102, 0, 0)\n",
    "# 0 255 102\n",
    "# (r, g, b) = (255, 0, 0)\n",
    "# 0 255 255\n",
    "\n",
    "# normalize\n",
    "(r, g, b) = (r / 255, g / 255, b / 255)\n",
    "#convert to hsv\n",
    "(h, s, v) = colorsys.rgb_to_hsv(r, g, b)\n",
    "#expand HSV range\n",
    "(h, s, v) = (int(h * 179), int(s * 255), int(v * 255))\n",
    "print('HSV : ', h, s, v)\n",
    "\n",
    "\n",
    "def prep(frame):\n",
    "    frame = imutils.resize(frame, width=600)\n",
    "    ## Todo 3.1.3 gaussian blur\n",
    "    blurred = frame\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, Lower, Upper)\n",
    "\n",
    "    ## Todo 3.1.3 gaussian blur\n",
    "    # mask =\n",
    "    # mask =\n",
    "    return mask, frame\n",
    "\n",
    "\n",
    "frame = cv2.imread('image.png')\n",
    "mask, frame = prep(frame)\n",
    "\n",
    "cv2.imshow(\"Image\", frame)\n",
    "cv2.imshow(\"Masked Image\", mask)\n",
    "cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a3a7c",
   "metadata": {},
   "source": [
    "### 3.1.3\n",
    "\n",
    "The above implementation provides a satisfactory result. However, when dealing with noisy images it is important to perform morphological transformations such as smoothing, erotion and dialation to get better results.\n",
    "\n",
    "**Your task**\n",
    "\n",
    "Read the following documentations and implement the following transformations inside the prep_frame() function above.\n",
    "\n",
    "\n",
    "- [x] Apply Gaussian blur with a kernel size of 11x11\n",
    "- [x] Apply erosion\n",
    "- [x] Apply dialation\n",
    "\n",
    "**References**\n",
    "\n",
    "- [Smoothing Images with OpenCV](https://docs.opencv.org/4.5.2/d4/d13/tutorial_py_filtering.html)\n",
    "- [Perform Erosion and Dialation on the image mask using OpenCV](https://docs.opencv.org/3.4/db/df6/tutorial_erosion_dilatation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7d793",
   "metadata": {},
   "source": [
    "### 3.1.4\n",
    "\n",
    "Finding contours in an image is useful in object detection and tracking. The code snippet below extracts contours from the image file and draws a circle with its center as the same center of detected contour. Execute the code below and observe the results.\n",
    "\n",
    "**References**\n",
    "- [ Detecting contours with OpenCV](https://docs.opencv.org/4.5.0/d4/d73/tutorial_py_contours_begin.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f3d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find contours and display\n",
    "def find_cnts(mask):\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    return cnts\n",
    "\n",
    "cnts = find_cnts(mask)\n",
    "c = max(cnts, key=cv2.contourArea)\n",
    "((x, y), radius) = cv2.minEnclosingCircle(c) ## A different contour?\n",
    "        \n",
    "# Find center of contour using moments in opencvq\n",
    "M = cv2.moments(c)\n",
    "center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "#circle\n",
    "frame1 = frame\n",
    "cv2.circle(frame1, (int(x), int(y)), int(radius),(0, 0, 255), 2)\n",
    "cv2.circle(frame1, center, 5, (0, 0, 255), -1)    \n",
    "cv2.imshow(\"Circle\", frame1)\n",
    "\n",
    "\n",
    "## ToDo 3.1.5 \n",
    "#  1. Bounding rectancgle\n",
    "#  2. Convex Hull\n",
    "\n",
    "\n",
    "cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce9729",
   "metadata": {},
   "source": [
    "### 3.1.5\n",
    "The above implementation only uses a minimum enclosing circle for labelling the detected image. There are more labelling options such as bounding boxes and convex hull which may come handy in various computer vision tasks.\n",
    "\n",
    "**Your task**\n",
    "\n",
    "- [x] Implement a bounding rectangle and rotated rectangle on the detected contours by modifying the code in 3.1.4 \n",
    "- [x] Implement a convex hull on the detected contours by modifying the code in 3.1.4\n",
    "\n",
    "**References**\n",
    "- [Contour features in OpenCV](https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html)\n",
    "- [Creating Bounding boxes and circles for contours](https://docs.opencv.org/4.x/da/d0c/tutorial_bounding_rects_circles.html)\n",
    "-[Convex Hull](https://docs.opencv.org/4.x/d7/d1d/tutorial_hull.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08eb8c4",
   "metadata": {},
   "source": [
    "***\n",
    "### 3.2 Object detection and Tracking with Video\n",
    "\n",
    "### 3.2.1\n",
    "\n",
    "Execute and observe the below code snippet which reads frames from a given video file at a pre-defined frame rate.\n",
    "\n",
    "**Your task**\n",
    "- [x] Implement pre-processing and find contour of the moving blob on by modifiying the same code below\n",
    "- [x] Implement a suitable labelling mode (Enclosed Circle / bounding Box or convex hull) and display the resulted tracking on a seperated window\n",
    "\n",
    "**Tip** : Use the same functions from 3.1. Avoid creating duplicate functions and unnecessarily lenghty code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cea68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "import imutils\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import colorsys\n",
    "\n",
    "vs = cv2.VideoCapture(\"test_video.avi\")\n",
    "time.sleep(2.0)\n",
    "\n",
    "frame_rate = 30\n",
    "prev = 0\n",
    "\n",
    "\n",
    "def prep(input_frame):\n",
    "    # Blue shapes\n",
    "    Lower = (90, 50, 70)\n",
    "    Upper = (128, 255, 255)\n",
    "\n",
    "\n",
    "    output_frame = imutils.resize(input_frame, width=800)\n",
    "    # output_frame = input_frame.copy()\n",
    "    ## Todo 3.1.3 gaussian blur\n",
    "    blurred = cv2.blur(output_frame, (11, 11))\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "    output_mask = cv2.inRange(hsv, Lower, Upper)\n",
    "\n",
    "    return output_mask, output_frame\n",
    "\n",
    "\n",
    "def find_cnts(input_mask):\n",
    "    # input: src_img, contour_mode, approx_method\n",
    "    # output: contours and hierarchy\n",
    "    # SIMPLE: two endpoints of the line\n",
    "    # NONE: all boundary points\n",
    "    threshold = 100\n",
    "    canny_output = cv2.Canny(input_mask, threshold, threshold * 2)\n",
    "    cnts = cv2.findContours(canny_output, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    return cnts\n",
    "\n",
    "\n",
    "def contour(input_frame, input_mask):\n",
    "    cnts = find_cnts(input_mask)\n",
    "\n",
    "    # c = cnts[5]\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    frame1 = input_frame.copy()\n",
    "    # for c in cnts:\n",
    "    ((x, y), radius) = cv2.minEnclosingCircle(c)  ## A different contour?\n",
    "    # print(cnts)\n",
    "\n",
    "    # Find center of contour using moments in opencvq\n",
    "    # M = cv2.moments(c)\n",
    "    # center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "    # circle\n",
    "    cv2.circle(frame1, (int(x), int(y)), int(radius), (0, 0, 255), 2)\n",
    "    cv2.circle(frame1, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "\n",
    "    # draw rectangle with green line\n",
    "    # contours_poly = cv2.approxPolyDP(c, 3, True)\n",
    "    # boundRect = cv2.boundingRect(contours_poly)\n",
    "    # cv2.rectangle(frame1, (int(boundRect[0]), int(boundRect[1])),\n",
    "    #               (int(boundRect[0] + boundRect[2]), int(boundRect[1] + boundRect[3])), (0, 255, 0), 1)\n",
    "\n",
    "    # draw rotate rectangle with blue line\n",
    "    # rect = cv2.minAreaRect(c)\n",
    "    # box = cv2.boxPoints(rect)\n",
    "    # box = np.int0(box)\n",
    "    # cv2.drawContours(frame1, [box], 0, (255, 0, 0), 1)\n",
    "\n",
    "    # draw Hull with pink line\n",
    "    # hull = cv2.convexHull(c)\n",
    "    # cv2.drawContours(frame1, [hull], 0, (255, 0, 255), 1)\n",
    "\n",
    "    cv2.imshow(\"Task 02 Circle\", frame1)\n",
    "\n",
    "\n",
    "while True:\n",
    "    time_elapsed = time.time() - prev\n",
    "\n",
    "    if time_elapsed > 1. / frame_rate:\n",
    "        frame = vs.read()\n",
    "        frame = frame[1]\n",
    "        if frame is None:\n",
    "            break\n",
    "        mask, frame = prep(frame)\n",
    "        contour(frame, mask)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        cv2.imshow(\"Masked Image\", mask)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        prev = time.time()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4da8f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###  3.3 Object detection and Tracking with ROS2\n",
    "\n",
    "### 3.3.1 \n",
    "\n",
    "In applications concerning robotic perception, so often visual data are obtained via camera sensors interfaced with ros. In this section you are provided with a ros-ignition simulation package which publish camera sensor data. The code snippet below subscribes to the camera sensor data and stream on to an OpenCV window. \n",
    "\n",
    "Assuming you have successfully build the package on your system using the instructions from handout, Open a New shell in you terminal and launch the simulation.\n",
    "\n",
    "```\n",
    "$ source /opt/ros/foxy/setup.bash\n",
    "$ cd ~/ws\n",
    "$ source install/setup.bash\n",
    "$ ros2 launch walking_actor cam_world.launch.py\n",
    "```\n",
    "\n",
    "While the simulation is running in background , run the code snippet below and observe the result\n",
    "\n",
    "- To close the cv2 window , select the window and press 'q'\n",
    "- To stop the execution of code snippet, double press on 'i' in keyboard or interrupt the kernel from menu\n",
    "\n",
    "\n",
    "**Your task**\n",
    "\n",
    "- [x] Modify the python code to track the walking actor. You can use any feature of the actor to track.\n",
    "- [x] Display the tracking in a seperate cv2 window\n",
    "\n",
    "\n",
    "**References**\n",
    "- [ROS2 python subscriber/publisher](https://docs.ros.org/en/foxy/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html)\n",
    "- [rclpy API Documentation](https://docs.ros2.org/foxy/api/rclpy/api/execution_and_callbacks.html#module-rclpy.executors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50719784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [1666519310.537348585] [Image_Subscriber]: Stopping the stream ...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from cv_bridge import CvBridge\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "#print(sys.path)\n",
    "\n",
    "bridge = CvBridge()\n",
    "\n",
    "class Get_Images(Node):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize the node\n",
    "        super().__init__('Image_Subscriber')\n",
    "        # Initialize the subscriber\n",
    "        self.subscription_ = self.create_subscription( Image,'/camera', self.listener_callback,10)\n",
    "        self.subscription_  # prevent unused variable warning\n",
    "        timer_period = 0.1  # seconds\n",
    "        self.timer = self.create_timer(timer_period, self.timer_callback)\n",
    "        self.K = True\n",
    "\n",
    "    def listener_callback(self, msg):\n",
    "        height = msg.height\n",
    "        width = msg.width\n",
    "        channel = msg.step//msg.width\n",
    "        #frame = np.reshape(msg.data, (height, width, channel))\n",
    "        self.frame =  bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\n",
    "        self.get_logger().info(\"Image Received\")\n",
    "        return self.frame\n",
    "    \n",
    "    def timer_callback(self):\n",
    "        if self.K == True:\n",
    "            cv2.imshow(\"Tracking\",self.frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord(\"q\"):\n",
    "                self.get_logger().info('Closing stream window..')\n",
    "                self.K = False\n",
    "                cv2.destroyAllWindows()\n",
    "        \n",
    "                \n",
    "    def stop_stream(self):\n",
    "        self.get_logger().info('Stopping the stream ...')\n",
    "        \n",
    "\n",
    "try:\n",
    "    \n",
    "    rclpy.init(args=None)\n",
    "    image_subscriber = Get_Images()\n",
    "    rclpy.spin(image_subscriber)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # executes on keyboard kernal interrupt with double pressing button \"i\"\n",
    "    image_subscriber.stop_stream()\n",
    "    image_subscriber.destroy_node()\n",
    "    rclpy.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracker",
   "language": "python",
   "name": "tracker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
